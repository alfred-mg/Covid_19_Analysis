---
title: "Covid !9 Analysis"
author: "Group Work"
date: "2023-11-09"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
rm(list = ls())

```



```{r, message=FALSE}

# Load required libraries
library(tidyverse)
library(lares) # show the structure of data
library(vtable) # show the mean, sd, min, max
library(caret) 
library(psycho) # Standardizing
library('DescTools')
library(ggcorrplot)
library(plotly) # Using plotly for interactive plots
library(fastDummies) # for dummy encoding

```



## About the Dataset

The data is about Coronavirus (COVID-19) Vaccinations

According to the website, the vaccination dataset uses the most recent official numbers from governments and health ministries worldwide. Population estimates for per-capita metrics are based on the United Nations World Population Prospects. Income groups are based on the World Bank classification. Source: https://ourworldindata.org/covid-vaccinations


**NB: The dataset should have at least 7000 rows and 10 columns after cleaning and there is not any upper
bound. The objectives of the DEP project are based on the domain knowledge of data. Need to complete
the following tasks during the development of this project.**


## Loading the Dataset


```{r}

# loading the data after downloading
data <- read.csv('owid-covid-data.csv')

dim(data)

# overview of the data
head(data, 5)

str(data)

```



### Checking for missing values


```{r, message=FALSE, warning=FALSE}

# Check for null values in the dataframe
is_null <- is.na(data)

# Count the number of null values in each column
num_null_values <- colSums(is_null, na.rm = TRUE)

# Print the number of null values in each column
print(num_null_values)

# show the details of the dataset
df_str(data, return = "plot")

```



As we can see from the above output, there are columns with a very high number of null values. So the first thing would be to drop all the columns whose number of null values is more more than half the total number of rows, or observations.

**Sometimes, R do not read empty strings, and question marks as nulls. So we first convert the Question marks and the empty strings as nulls then check the number of null values.



```{r}

# Replace question marks with NA in the entire dataframe
data[data == "?"] <- NA

# Replace empty strings with NA in the entire dataframe
data[data == ""] <- NA

# Check for null values in each column
null_counts <- colSums(is.na(data))

# Get columns where more than half of the values are null
columns_to_drop <- names(null_counts[null_counts > nrow(data)/2])

# Drop columns with more than half of the values being null
data <- data[, !names(data) %in% columns_to_drop]

dim(data)

# Drop rows with NA values using na.omit()
data <- na.omit(data)

# Check for null values in the dataframe
is_null <- is.na(data)

# Count the number of null values in each column
num_null_values <- colSums(is_null, na.rm = TRUE)

# Print the number of null values in each column
print(num_null_values)

View(data)
```


We can now see that we do not have any null values in the columns.


### Dropping all the Null Values


```{r}

# Drop rows with NA values using na.omit()
data_clean <- na.omit(data)

# checking the shape of the data
cat('The shape of the data:', dim(data_clean)[1], 'rows/observations', 'and', dim(data_clean)[2], 'columns')

```


The Dataset is already eligible for our analysis as it means the eligibility of 7000 and 10 columns




### Removing Unwanted Columns


```{r}

# Removing a single column using subset() function
data <- subset(data, select = -c(population, human_development_index, life_expectancy, 
                                 hospital_beds_per_thousand, male_smokers, female_smokers,
                                 diabetes_prevalence, cardiovasc_death_rate, gdp_per_capita,
                                 aged_70_older, aged_65_older, median_age, population_density,
                                 stringency_index, new_people_vaccinated_smoothed_per_hundred, 
                                 new_vaccinations_smoothed_per_million, new_deaths_smoothed_per_million,
                                 new_deaths_per_million, total_deaths_per_million, new_cases_smoothed_per_million,
                                 new_cases_per_million, total_cases_per_million))

dim(data)
```



### A. Identify which variables are categorical, discrete and continuous in the chosen data set and show using some visualization or plot. Explore whether there are missing values for any of the variables.



```{r}

# Remove all instances of 0 from all columns
data_no_zeros <- data
data_no_zeros[data_no_zeros == 0] <- NA
data <- na.omit(data_no_zeros)

# Check data types of variables
str(data)

```


```{r, warning=FALSE, message=FALSE}

# show the details of the dataset
df_str(data, return = "plot")

```

### Identify which variables are categorical, discrete and continuous in the chosen data set


* Categorical Variables

- iso_code
- continent
- location
- date


* Discrete Variables

- total_cases
- new_cases
- total_deaths
- new_deaths
- new_vaccinations_smoothed 
- new_people_vaccinated_smoothed

* Continous Variables

- new_cases_smoothed
- new_deaths_smoothed
- reproduction_rate



### B. Calculate the statistical parameters (mean, median, minimum, maximum, and standard deviation) for each of the numerical variables. 




```{r}

# Select numerical columns using indexing
numerical_data <- data[sapply(data, is.numeric)]

numerical_data  %>%
      pivot_longer(everything()) %>%
      group_by(name) %>%
       summarise_at(vars(value), list(Mean = mean, Median = median, Min = min,  Max = max, Sd = sd))

# getting the summary statistics
st(numerical_data)

```




### C. Apply Min-Max Normalization, Z-score Standardization and Robust scalar on the numerical data variables.


#### Min-Max Normalization


```{r}

# Apply Min-Max Normalization
preproc <- preProcess(numerical_data, method = c("range"))
scaled_data_minmax <- predict(preproc, numerical_data)
scaled_data_minmax

```



#### Z-score Standardization


```{r}

# Z-score standardization
z_score_standardized_data <- as.data.frame(scale(numerical_data))
print(z_score_standardized_data)

```



#### Robust scalar


```{r}

# Robust Scalar
robust_scalar <- function(x){(x- median(x)) /(quantile(x,probs = .75)-quantile(x,probs = .25))}
robust_scalar_data <- as.data.frame(sapply(numerical_data, robust_scalar))
robust_scalar_data

```



### D. Line, Scatter and Heatmaps can be used to show the correlation between the features of the dataset.


#### Line Plots


#### Total Cases vs Total Deaths


```{r}

# Basic line plot
ggplot(data=data, aes(x=total_cases, y=total_deaths))+
  geom_line(color= 'black') +
  labs(title = "Scatter Plot of Total Cases vs Total Deaths")

```



#### Line Chart of New Deaths and New Deaths Smoothed


```{r}

# Convert 'date' column to Date type if it's not already
data$date <- as.Date(data$date)
# Plot 'new deaths' and 'new deaths smoothed' against dates with different colors for each line
ggplot(data, aes(x = date)) +
  geom_line(aes(y = new_deaths, color = "New deaths")) +
  geom_line(aes(y = new_deaths_smoothed, color = "New deaths smoothed")) +
  scale_color_manual(values = c("New deaths" = "blue", "New deaths smoothed" = "green")) +
  labs(title = "New Deaths and New Deaths Smoothed Over Time", x = "Date", y = "Number of Cases", color = "Legend") +
  theme_minimal()

```


#### Line Chart of Total Cases VS Total Deaths With Time


```{r}

# Convert 'date' column to Date type if it's not already
ggplot(data, aes(x = date)) +
  geom_line(aes(y = total_cases, color = "total cases")) +
  geom_line(aes(y = total_deaths, color = "total deaths")) +
  scale_color_manual(values = c("total cases" = "red", "total deaths" = "green")) +
  labs(title = "Total Cases and Total Deaths Over Time", x = "Date", y = "Number of Cases", color = "Legend") +
  theme_minimal()

```


#### Scatter Plots


#### Scatter Plot of Total Deaths Vs Total Cases



```{r}

# Plot scatter plot of 'total_cases' vs 'total_deaths' with different colors for each data point
ggplot(data, aes(x = total_cases, y = total_deaths, color = factor(continent))) +
  geom_point(size = 0.5) +
  labs(title = "Scatter Plot of Total Cases vs Total Deaths", 
       x = "Total Cases", y = "Total Deaths", color = "Continent") +
  theme_minimal()

```




#### Heatmaps can be used to show the correlation between the features of the dataset


```{r}

# Compute a correlation matrix
corr <- round(cor(numerical_data), 1)

# Compute a matrix of correlation p-values
p.mat <- cor_pmat(numerical_data)

# Reordering the correlation matrix using hierarchical clustering
ggcorrplot(corr, hc.order = TRUE)

```




```{r}

# Barring the no significant coefficient
ggcorrplot(corr, hc.order = TRUE, p.mat = p.mat)

```


```{r}

# Calculate the correlation matrix
correlation_matrix <- cor(numerical_data)

# Reshape the correlation matrix for plotting
correlation_data <- as.data.frame(as.table(correlation_matrix))
colnames(correlation_data) <- c("Feature1", "Feature2", "Correlation")

# Create a heatmap of the correlation matrix with rotated x-axis labels
ggplot(data = correlation_data, aes(x = Feature1, y = Feature2, fill = Correlation)) +
  geom_tile() +
  scale_fill_gradient(low = "white", high = "darkblue") +
  labs(title = "Correlation Heatmap", x = "Feature 1", y = "Feature 2") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```



### E. Graphics and descriptive understanding should be provided along with Data Exploratory analysis (EDA). Identify subgroups of features that can explore some interesting facts.


#### Total Deaths Per Continent


```{r}

# Group data by continent and calculate total deaths for each continent
continent_deaths <- data %>%
  group_by(continent) %>%
  summarise(total_deaths = sum(total_deaths, na.rm = TRUE))

# Create a bar chart of total deaths by continent
ggplot(data = continent_deaths, aes(x = continent, y = total_deaths, fill = continent)) +
  geom_bar(stat = "identity") +
  labs(title = "Total Deaths by Continent", x = "Continent", y = "Total Deaths") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate x-axis labels for better readability

```


#### Total Cases Per Continent


```{r}

# Group data by continent and calculate total cases for each continent
continent_cases <- data %>%
  group_by(continent) %>%
  summarise(total_cases = sum(total_cases, na.rm = TRUE))

# Create a bar chart of total cases by continent
ggplot(data = continent_cases, aes(x = continent, y = total_cases, fill = continent)) +
  geom_bar(stat = "identity") +
  labs(title = "Total Cases by Continent", x = "Continent", y = "Total Cass") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate x-axis labels for better readability

```


```{r}

# Manually specify colors for the continents
continent_colors <- c("Asia" = "red", "Africa" = "orange", "Europe" = "green", 
                      "North America" = "blue", "Oceania" = "purple", "South America" = "yellow")

# Plot line chart of 'total_cases' over time per continent with manual colors and increased transparency
ggplot(data, aes(x = date, y = total_cases, color = continent)) +
  geom_line(alpha = 0.5) +  # Set the alpha value (transparency) to 0.6
  scale_color_manual(values = continent_colors) +
  labs(title = "Total Cases Over Time by Continent", x = "Date", y = "Total Cases", color = "Continent") +
  theme_minimal()

```

```{r}

ggplot(data, aes(x = date, y = total_cases, color = continent, linetype = continent)) +
  geom_line() +
  scale_color_manual(values = continent_colors) +
  scale_linetype_manual(values = c("Asia" = "solid", "Africa" = "dashed", "Europe" = "dotted", 
                                   "North America" = "dotdash", "Oceania" = "longdash", 
                                   "South America" = "twodash")) +
  labs(title = "Total Cases Over Time by Continent", x = "Date", y = "Total Cases", color = "Continent") +
  theme_minimal()

```


```{r}

ggplot(data, aes(x = date, y = total_cases, color = continent)) +
  geom_line() +
  scale_color_manual(values = continent_colors) +
  facet_wrap(~continent, scales = "free_y") +
  labs(title = "Total Cases Over Time by Continent", x = "Date", y = "Total Cases", color = "Continent") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

```{r}

plot_ly(data, x = ~date, y = ~total_cases, color = ~continent, type = "scatter", mode = "lines") %>%
  layout(title = "Total Cases Over Time by Continent", xaxis = list(title = "Date"), 
         yaxis = list(title = "Total Cases"), legend = list(title = "Continent"))

```



#### Total Deaths Per Countries Per Continent


#### European Countries


```{r}

# Filter data for Europe
europe_data <- data %>% 
  filter(continent == "Europe")

# Bar plot for Europe
ggplot(europe_data, aes(x = location, y = total_deaths, fill = location)) +
  geom_bar(stat = "identity") +
  scale_fill_viridis_d() +  # Use viridis color scale
  labs(title = "Total Deaths in European Countries", x = "Countries", y = "Tota Deaths") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  theme(legend.position = "none")  # Remove the legend

```


#### Asian Countries


```{r}

# Filter data for Asia
asia_data <- data %>% 
  filter(continent == "Asia")

# Bar plot for Asia
ggplot(asia_data, aes(x = location, y = total_deaths, fill = location)) +
  geom_bar(stat = "identity") +
  scale_fill_viridis_d() +  # Use viridis color scale
  labs(title = "Total Deaths in Asian Countries", x = "Countries", y = "Tota Deaths") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  theme(legend.position = "none")  # Remove the legend

```


#### African Countries


```{r}

# Filter data for Africa
africa_data <- data %>% 
  filter(continent == "Africa")

# Bar plot for Africa
ggplot(africa_data, aes(x = location, y = total_deaths, fill = location)) +
  geom_bar(stat = "identity") +
  scale_fill_viridis_d() +  # Use viridis color scale
  labs(title = "Total Deaths in African Countries", x = "Countries", y = "Tota Deaths") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  theme(legend.position = "none")  # Remove the legend

```



#### Oceania Countries


```{r}

# Filter data for Oceania
Oceania_data <- data %>% 
  filter(continent == "Oceania")

# Bar plot for Oceania
ggplot(Oceania_data, aes(x = location, y = total_deaths, fill = location)) +
  geom_bar(stat = "identity") +
  scale_fill_viridis_d() +  # Use viridis color scale
  labs(title = "Total Deaths in Oceanic Countries", x = "Countries", y = "Tota Deaths") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  theme(legend.position = "none")  # Remove the legend

```


#### South America Countries


```{r}

# Filter data for South America
south.america_data <- data %>% 
  filter(continent == "South America")

# Bar plot for South America
ggplot(south.america_data, aes(x = location, y = total_deaths, fill = location)) +
  geom_bar(stat = "identity") +
  scale_fill_viridis_d() +  # Use viridis color scale
  labs(title = "Total Deaths in South American Countries", x = "Countries", y = "Tota Deaths") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  theme(legend.position = "none")  # Remove the legend

```


#### North America Countries


```{r}

# Filter data for North America
north.america_data <- data %>% 
  filter(continent == "North America")

# Bar plot for North America
ggplot(north.america_data, aes(x = location, y = total_deaths, fill = location)) +
  geom_bar(stat = "identity") +
  scale_fill_viridis_d() +  # Use viridis color scale
  labs(title = "Total Deaths in North American Countries", x = "Countries", y = "Tota Deaths") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  theme(legend.position = "none")  # Remove the legend

```



### F. Apply dummy encoding to categorical variables (at least one variable used from the data set) and discuss the benefits of dummy encoding to understand the categorical data.


```{r}

# Selects all columns that are factors
categorical_data <- select_if(data, is.character)

# create dummy variables of continent
categorical_data <- dummy_cols(categorical_data, select_columns = c("continent"), remove_selected_columns = TRUE)

# drop unuseful columns
categorical_data <- subset(categorical_data, select = -c(iso_code, location))
categorical_data

```
































